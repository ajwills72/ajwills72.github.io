---
layout: post
title: How hard is cognitive science?
subtitle: Very, very hard
cover-img: /assets/img/cogscihard.png
thumbnail-img: /assets/img/cogscihard.png
share-img: /assets/img/cogscihard.png
gh-repo: daattali/beautiful-jekyll
tags: [theory]
comments: true
---

Patricia Rich and colleagues [(Rich et al., 2021)](https://psyarxiv.com/k79nv) ask us to imagine what, for most theorists in cognitive science, would seem to be an ideal working environment. It's a world where there is no uncertainty about observations (no replication crisis). It's also a world where there is no problem of induction (cf. Goodman)  - the theorist has full, automatic access to all observations, past and future. And it's a world where we somehow knew that there was only one theory that was consistent with the data (cf. Kuhn). 

Surely, then, coming up with the right theory would be something we could definitely do, given sufficient time and resources? The answer, they argue, is "no". Finding the correct theory is computationally intractable - meaning that even if we could use every atom in the universe as a computer and used all the time that has so far passed in the universe on this universe-computer, that would still not be enough to be sure of finding the right theory.

The basic problem is that the space of theories one would have to check against the data are astronomically large, even if you're only looking for an approximate explanation (say, 50% of the facts) of a subset of behaviour (e.g. the ones you think are important), using the subset of theories you are interested in (e.g. connectionist accounts).

The consolation Patricia and colleagues leave us with is that, if we hit the correct explanation by sheer luck, we'd be able to recognise that it was the right explanation. Not much of a consolation.

This is all very much my first impression of this interesting paper. One thing that I definitely need to think some more about is that the proofs of these claims seem to be specific to certain types of 'languages' in which the theories are expressed (hence e.g. "for some Lf" in Theorem 3). The supplementary materials seem to show that finite-state automata, ACT-R, and some other, more recent, languages are among that set. What is less clear to me is if there exists, or could exist, a language for which this would not apply. And, if so, whether the problem of finding such a langauge would in itself be intractable.

Another thing is that I wonder whether the assumption there is exactly one correct theory makes the problem particularly difficult. If there are in fact a large number of reasonably adequate theories, finding one of them should not be so hard. 

A related point - I think the authors are relying on calculating the amoutn of time to be sure of finding the correct answer. Would this therefore be a type of worst-case scenario, where it could take that long, but we'd be extraordinarily unlucky for it to do so? For example, do the conclusions differ if we estimate the time elapsed before finding the solution 50% of the time?

So, to emphasize, these are initial thoughts on a fascinating paper, and it's very possible the authors have already thought about and addressed these thoughts. Either way, thanks Patricia, Ronald, Todd, and Iris, great work!


Image by Rich et al.
